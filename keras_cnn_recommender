with mlflow.start_run(run_name=runName):

  mlflow.tensorflow.autolog()   

  #Build the model, compile and train on the training set
  #signature: build_model(vocab_size, steps, drop_embed, n_dim, encoder, modelType):
  keras_model = build_model((vocab_size + 1), timeSteps, drop_embed, embedding_dimensions, encoder, modelType)      

  # CREATE CALLBACKS      
  #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=experiment_log_dir)
  #model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_best_only=True)
  #early_stopping = EarlyStopping(monitor="loss", mode="min", patience=3)
  
  modelcheckpoint = ModelCheckpoint(filepath=output_dir+"/weights.{epoch:02d}.hdf5")

  keras_model.fit(X_train_encoded, y_train_encoded, epochs=epochs, verbose=1, batch_size=32, use_multiprocessing = True, 
                            validation_data=(X_test_encoded, y_test_encoded), callbacks=[modelcheckpoint])

  # Log the model parameters used for this run.  
  mlflow.log_param("numofActionsinWorkflow", numofActionsinWf)
  mlflow.log_param("timeSteps", timeSteps)

  # Create a model signature using the tensor input to store in the MLflow model registry
  signature = infer_signature(X_test_encoded, keras_model.predict(X_test_encoded))
  # Let's check out how it looks
  print(signature)

  # Create an input example to store in the MLflow model registry
  input_example = np.expand_dims(X_train[17], axis=0)
  
  #log the model to experiment
  mlflow.keras.log_model(keras_model, artifact_path = runName, signature=signature, input_example=input_example)

  #return the run ID for model registration
  run_id = mlflow.active_run().info.run_id
  
  mlflow.end_run()
